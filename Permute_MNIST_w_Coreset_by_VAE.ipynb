{"cells":[{"cell_type":"markdown","id":"0vJO8cjK1AG7","metadata":{"id":"0vJO8cjK1AG7"},"source":["Last Update: 3/14/2023\n","\n","This notebook contains codes and results of VCL on permute MNIST dataset with Coresets using embeddings by VAE.\n","\n"]},{"cell_type":"code","execution_count":1,"id":"Wx6wdX4Jp3y_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17599,"status":"ok","timestamp":1678316077258,"user":{"displayName":"Jiajun He","userId":"11208084986033535177"},"user_tz":0},"id":"Wx6wdX4Jp3y_","outputId":"3f645f0a-66c3-4e30-89db-4f2a02bcfdad"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"id":"39e4e68f","metadata":{"id":"39e4e68f"},"outputs":[],"source":["import torch\n","from torch import nn\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","from torch.distributions import kl_divergence, Normal\n","from collections import OrderedDict\n","from torchvision import datasets\n","from torchvision import transforms\n","import pickle\n","\n","from alg.coreset import Coreset, CoresetConfig"]},{"cell_type":"code","execution_count":2,"id":"3d4adf7f","metadata":{"id":"3d4adf7f"},"outputs":[],"source":["class BayesLinear(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super().__init__()\n","        self.weight_loc = nn.Parameter(torch.zeros(in_features, out_features))\n","        self.log_weight_scale = nn.Parameter(torch.zeros(in_features, out_features))\n","        \n","        self.bias_loc = nn.Parameter(torch.zeros(out_features))\n","        self.log_bias_scale = nn.Parameter(torch.zeros(out_features))\n","        \n","    def get_params(self):\n","        \"\"\"\n","        return two tensors, obtaining by concatenating locs and scales together\n","        these parameters can be further used to calculate e.g, KL divergence (vectorizedly)\n","        \"\"\"\n","        return (\n","                torch.cat([self.weight_loc.flatten(), self.bias_loc.flatten()]), \n","                torch.cat([self.log_weight_scale.flatten(), self.log_bias_scale.flatten()])\n","               )\n","    \n","    def forward(self, x, x_is_sample, activition_fn, n_particles):\n","        \"\"\"\n","        forward with local reparameterization tricks\n","        \"\"\"\n","        ys = []\n","        if x_is_sample:\n","            assert n_particles == len(x)\n","            for _x in x:\n","                gamma = _x @ self.weight_loc + self.bias_loc\n","                delta2 = (_x ** 2) @ (torch.exp(self.log_weight_scale) ** 2) + torch.exp(self.log_bias_scale) ** 2\n","                y = gamma + torch.randn_like(gamma) * torch.sqrt(delta2 + 1e-6) \n","                ys.append(activition_fn(y))\n","        else:\n","            for _ in range(n_particles):\n","                gamma = x @ self.weight_loc + self.bias_loc\n","                delta2 = (x ** 2) @ (torch.exp(self.log_weight_scale) ** 2) + torch.exp(self.log_bias_scale) ** 2\n","                y = gamma + torch.randn_like(gamma) * torch.sqrt(delta2 + 1e-6) \n","                ys.append(activition_fn(y))\n","        return ys\n","    \n","    def forward_MLE(self, x, activition_fn):\n","        y = x @ self.weight_loc + self.bias_loc\n","        return activition_fn(y)\n"]},{"cell_type":"code","execution_count":3,"id":"7049e8a0","metadata":{"id":"7049e8a0"},"outputs":[],"source":["# Implement Gonzalez Algorithm for k-Center Clustering for Coreset selection\n","\n","class KCenter:\n","    def __init__(self, K):\n","        self.K = K\n","    def fit_transform(self, x):\n","        # fit and return centers\n","        idx1 = np.random.choice(x.shape[0], 1)\n","        center = x[idx1] # (1, d)\n","        idx = [idx1.item()]\n","        min_distances_to_centers = np.full([1, x.shape[0]], np.inf)\n","        for k in tqdm(range(1, self.K)):\n","            distances = ((x[None, :, :] - center[:, None, :]) ** 2).sum(-1) # 1, N\n","            min_distances_to_centers = np.vstack([min_distances_to_centers, distances]).min(0)\n","            new_center_idx = np.argmax(min_distances_to_centers).item()\n","            idx.append(new_center_idx)\n","            center = x[[new_center_idx]]\n","        assert len(idx) == self.K\n","        return idx"]},{"cell_type":"code","execution_count":4,"id":"4413bd53","metadata":{"id":"4413bd53"},"outputs":[],"source":["class VCL_permute_MNIST(nn.Module):\n","    def __init__(self, previous_model, random_initialize):\n","        super().__init__()\n","        \n","        # \"fully connected single-head networks with two hidden layers, where each layer contains 100 hidden units with ReLU activation\"\n","        self.linear1 = BayesLinear(28*28, 100)\n","        self.linear2 = BayesLinear(100, 100)\n","        self.head = BayesLinear(100, 10)\n","        \n","        # intialize distributions as prior distributions\n","        # I believe there exist better ways to do this, but I am too lazy to think..(sorry)\n","        \n","        # define a layer dict\n","        self.layer_dict = OrderedDict()\n","        self.layer_dict[\"linear1\"] = self.linear1\n","        self.layer_dict[\"linear2\"] = self.linear2\n","        self.layer_dict[\"head\"] = self.head\n","        \n","        # just a sanity check \n","        assert id(self.layer_dict[\"linear1\"]) == id(self.linear1)\n","        \n","        \n","        with torch.no_grad():\n","            if previous_model != None:\n","                for key in self.layer_dict:\n","                    self.layer_dict[key].weight_loc.data = previous_model.layer_dict[key].weight_loc.data.clone()\n","                    self.layer_dict[key].bias_loc.data = previous_model.layer_dict[key].bias_loc.data.clone()\n","                    self.layer_dict[key].log_weight_scale.data  = previous_model.layer_dict[key].log_weight_scale.data.clone()\n","                    self.layer_dict[key].log_bias_scale.data  = previous_model.layer_dict[key].log_bias_scale.data.clone()\n","            if random_initialize: \n","                # the first model's initialization\n","                # 0 mean and very small variances (do not need to break the symmetricity since the training is based on random samples)\n","                for key in self.layer_dict:\n","                    self.layer_dict[key].weight_loc.data = torch.randn_like(self.layer_dict[key].weight_loc.data) * 0.1\n","                    self.layer_dict[key].bias_loc.data = torch.randn_like(self.layer_dict[key].bias_loc.data) * 0.1\n","                    # initialize to very small value for the first model\n","                    self.layer_dict[key].log_weight_scale.data  = torch.zeros_like(self.layer_dict[key].log_weight_scale.data) - 10\n","                    self.layer_dict[key].log_bias_scale.data  = torch.zeros_like(self.layer_dict[key].log_bias_scale.data) - 10\n","        \n","        # also save parameters of the previous model, for the calculation of ELBO\n","        if  previous_model != None:\n","            previous_locs, previous_logscales = previous_model.get_params()\n","            previous_locs, previous_logscales = previous_locs.detach().clone(), previous_logscales.detach().clone()\n","            self.previous_model_locs = previous_locs\n","            self.previous_model_log_scales = previous_logscales\n","        else:\n","            self.previous_model_locs = None\n","            self.previous_model_log_scales = None\n","        \n","    def predict(self, x, n_particles):\n","        hiddens =  self.linear1.forward(x, x_is_sample=False, activition_fn=nn.ReLU(), n_particles=n_particles)\n","        hiddens =  self.linear2.forward(hiddens, x_is_sample=True, activition_fn=nn.ReLU(), n_particles=n_particles)\n","        logits = self.head.forward(hiddens, x_is_sample=True, activition_fn=nn.Identity(), n_particles=n_particles)\n","        return logits # a list of logits calculated from samples\n","    \n","    def predict_MLE(self, x):\n","        hiddens =  self.linear1.forward_MLE(x, nn.ReLU())\n","        hiddens =  self.linear2.forward_MLE(hiddens, nn.ReLU())\n","        logits = self.head.forward_MLE(hiddens, nn.Identity())\n","        return logits\n","    \n","    def get_params(self):  \n","        locs = []\n","        logscales = []\n","        for key in self.layer_dict:\n","            loc, scale = self.layer_dict[key].get_params()\n","            locs.append(loc)\n","            logscales.append(scale)\n","        locs = torch.cat(locs)\n","        logscales = torch.cat(logscales)\n","        return locs, logscales\n","    \n","    def calculate_ELBO(self, x, y, n_particles, dataset_size):\n","        \n","        locs, logscales = self.get_params()\n","        # calculate KL between \"prior\" and posterior\n","        KL = kl_divergence(Normal(loc=locs, scale=torch.exp(logscales)),\n","                           Normal(loc=self.previous_model_locs, scale=torch.exp(self.previous_model_log_scales))\n","                          )\n","        nELBO = 0 \n","        for _ in range(n_particles):\n","            logit = self.predict(x, 1)[0]\n","            neg_log_p = nn.CrossEntropyLoss(reduction='sum')(logit, y)\n","            nELBO = neg_log_p + nELBO\n","        nELBO = nELBO / n_particles / x.shape[0] + KL.sum() / dataset_size \n","        # since the ELBO can be viewed as an MC estimator over dataset. Keep the magnitude same is of vital importance!!!\n","                  \n","        return nELBO  \n","    def MLE_loss(self, x, y):\n","        logit = self.predict_MLE(x)\n","        loss = nn.CrossEntropyLoss(reduction='mean')(logit, y)\n","        return loss\n"]},{"cell_type":"code","execution_count":5,"id":"a514cbef","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["40c39a4d63774220b219e440af38c14a","5c9317678e1446cf87760a297b02b426","df700a9dbba3473f81cbd04515f01dc6","c7827847da6a485586d686ae2609db0d","1b7f1c6e6ad744489a902dffc1dd5090","36178f80a99b49f38cae0a86e53addcb","013925e264834599a452ba23c3d14f87","8a664e2628d54d2997e9eaee85fa40f9","3b903ed1907d4b0b999f8f412e99e7b3","85d88060ee4e48d2863d500c8dc126ca","f0198315a5ac4b2b8a54e4f885984c8c","34ae145f8de941dd9b229582b1ca0ddf","99b4aa392a0a4ffda3a34abb75ff4ad8","21a51e5f20a845b9bf04c55b021bbe21","7eb525148f90423c84d30dfba68aaf0f","9ca4bae40e6041b59457bfcf77943b36","48ff1a06940d41039d06c508e09b3dab","c36d4e95255d4dd58ce7511b6ce0e63f","d75c83f803fd45e09dcba05c2f39c6d0","32cb5d519d234f159278b4918d452ee0","138b4c88fea941ccad005afb8c89576c","d277df76b23947159431df94442952bb","1c9b00bceb1544e78228be3e72b5c293","f4afd3484fda4398960a2e49b45f3c8e","3c3186242d384c508635b2e1e3be39d1","cb8c323fa82c4ff1a388dd510f3a5323","111b8b1004df4ef3b03986eb77b27306","723675e7685e40bf81d34d4af2a087a9","e6b5a150126141e2a4128cd7c096852a","df75ad974e75418885f10f7ff1596462","e657fea4955c4ccaa5349c80c5a2ec98","4ae4258ee979445fb3c750e759162de5","41938c7b57f54b16ae343d7f7f1ecfe1","af425e13852245ff86f4f49741793c05","cc2d9b1e75bb471a8d635eccf8d9d1a3","857d8d542e9548dd94131b8432fdd122","7074a85086994b83be9a1a33d25f7494","a5537173fa5448cd97cf82656c13c813","2f08315dc19e44cda8cef02b3a76330a","ae5980193b6b4412b27fb7da58d12f2c","c924cb85b61b407083dd1d0d02daddec","9e2bc882f19d49519a286b7c9c03287c","bebc51e2fff8425f97c005eab6b3a7bd","2597272853ea4cbca38b7df239b34d66"]},"executionInfo":{"elapsed":1027,"status":"ok","timestamp":1678316082427,"user":{"displayName":"Jiajun He","userId":"11208084986033535177"},"user_tz":0},"id":"a514cbef","outputId":"dc6a8205-6470-4ec7-a288-19932222c1eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f64d42bcb91348fbaf75b4fd09c8789a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76624fe65ce7446e8db236f4275a0779","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8079c58dfbf34a38a0c5d67e41dc38e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22d75b886847448c8a1fb371611f7f0c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]}],"source":["ds_test = datasets.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)\n","ds_train = datasets.MNIST(\"./\", train=True, transform=transforms.ToTensor(), download=True)\n","def get_pMNIST(task_idx, device):\n","    np.random.seed(task_idx)\n","    permute_idx = np.random.choice(28*28, 28*28, False)\n","    train_x = nn.Flatten()(torch.cat([d[0] for d in ds_train]))[:, permute_idx]\n","    train_y = torch.tensor([d[1] for d in ds_train])\n","    \n","    test_x = nn.Flatten()(torch.cat([d[0] for d in ds_test]))[:, permute_idx]\n","    test_y = torch.tensor([d[1] for d in ds_test])\n","    \n","    return train_x.to(device), train_y.to(device), test_x.to(device), test_y.to(device)"]},{"cell_type":"code","execution_count":6,"id":"b7de0764","metadata":{"id":"b7de0764"},"outputs":[],"source":["device = \"cuda\""]},{"cell_type":"markdown","id":"kYFOgxa5oisU","metadata":{"id":"kYFOgxa5oisU"},"source":["### Compare different coreset size. "]},{"cell_type":"code","execution_count":7,"id":"VUJ_ImRoo14f","metadata":{"id":"VUJ_ImRoo14f"},"outputs":[],"source":["def run_experiments(save_file_name, coreset_config=None):\n","    previous_model = VCL_permute_MNIST(previous_model=None, random_initialize=False).to(device) # initialize a prior model\n","    Test_x = []\n","    Test_y = []\n","\n","    batch_size = 256\n","\n","    Accuracies = []\n","\n","    n_epochs = 200\n","\n","    coreset = Coreset(coreset_config)\n","\n","    for task in tqdm(range(10), desc='Running', position=1, leave=False):\n","        train_x, train_y, test_x, test_y = get_pMNIST(task, device)\n","        Test_x.append(test_x)\n","        Test_y.append(test_y)\n","        \n","        # define current model\n","        current_model = VCL_permute_MNIST(previous_model=previous_model, random_initialize=True).to(device)\n","        current_opt = torch.optim.Adam(current_model.parameters(), lr=0.001)\n","\n","        ##################################################################################################\n","        #INSERT YOUR VAE CODES HERE!\n","        # Trained with train_x, return coreset_idx\n","\n","        train_x, train_y = coreset.update(train_x, train_y, task)\n","\n","\n","        ##################################################################################################\n","\n","        ELBO = []\n","        for epoch in tqdm(range(n_epochs), desc='Training propagation model', position=2, leave=False):\n","            ELBO_batch = []\n","            for batch in range(int(np.ceil(train_x.shape[0] / batch_size))):\n","                batch_idx0 = batch * batch_size\n","                batch_idx1 = batch * batch_size + batch_size\n","                \n","                current_opt.zero_grad()\n","                elbo = current_model.calculate_ELBO(x=train_x[batch_idx0: batch_idx1], \n","                                                    y=train_y[batch_idx0: batch_idx1], \n","                                                    n_particles=1,\n","                                                    dataset_size=train_x.shape[0])\n","                elbo.backward()\n","                nn.utils.clip_grad_value_(current_model.parameters(), 5)\n","                current_opt.step()\n","                ELBO_batch.append(elbo.item())\n","            ELBO.append(np.mean(ELBO_batch))\n","            \n","        # calculate prediction model\n","        pred_model = VCL_permute_MNIST(previous_model=current_model, random_initialize=False).to(device)\n","        pred_opt = torch.optim.Adam(pred_model.parameters(), lr=0.001)\n","\n","        ELBO = []\n","        for epoch in tqdm(range(n_epochs), desc='Training predictive model', position=2, leave=False):\n","            ELBO_batch = []\n","            for batch in range(int(np.ceil(coreset.x.shape[0] / batch_size))):\n","                batch_idx0 = batch * batch_size\n","                batch_idx1 = batch * batch_size + batch_size\n","                pred_opt.zero_grad()\n","                elbo = pred_model.calculate_ELBO(x=coreset.x[batch_idx0: batch_idx1], \n","                                                y=coreset.y[batch_idx0: batch_idx1], \n","                                                n_particles=1,\n","                                                dataset_size=coreset.x.shape[0])\n","                elbo.backward()\n","                nn.utils.clip_grad_value_(pred_model.parameters(), 5)\n","                pred_opt.step()\n","                ELBO_batch.append(elbo.item())\n","            ELBO.append(np.mean(ELBO_batch))\n","\n","        test_x_tensor = torch.cat(Test_x)\n","        test_y_tensor = torch.cat(Test_y)\n","        pred_y = []\n","        with torch.no_grad():\n","            for batch in range(int(np.ceil(test_x_tensor.shape[0] / batch_size))):\n","                batch_idx0 = batch * batch_size\n","                batch_idx1 = batch * batch_size + batch_size\n","                pred_logit_samples = nn.Softmax(-1)(torch.stack(pred_model.predict(test_x_tensor[batch_idx0: batch_idx1], 100), 0)).mean(0)\n","                pred_y.append(pred_logit_samples.argmax(-1))\n","            pred_y = torch.cat(pred_y)\n","            acc = (pred_y == test_y_tensor).cpu().numpy().mean()\n","        Accuracies.append(acc)\n","        # print(\"Task {:d}, Accuracy: {:.4f}\".format(task, acc))\n","        previous_model = current_model\n","\n","\n","    # print(Accuracies)\n","\n","    with open(save_file_name, \"wb\") as f:\n","        pickle.dump(Accuracies, f)\n","    return Accuracies"]},{"cell_type":"code","execution_count":8,"id":"c2zsstj2aSlp","metadata":{"id":"c2zsstj2aSlp"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4580cd52201c459ab439d5f471245ac7","version_major":2,"version_minor":0},"text/plain":["Running experiment:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96eb85d5667842808ed93217aa4cb08b","version_major":2,"version_minor":0},"text/plain":["Running:   0%|          | 0/10 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Running normal VAE\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"107693b3fd02465eb34f4fef116cb6c9","version_major":2,"version_minor":0},"text/plain":["Training propagation model:   0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m), desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRunning experiment\u001b[39m\u001b[39m\"\u001b[39m, position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# print(\"====================== Run %d =====================\"%i)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     config \u001b[39m=\u001b[39m CoresetConfig(\u001b[39m'\u001b[39m\u001b[39mvae-k-center\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39m200\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     Accuracies \u001b[39m=\u001b[39m run_experiments(save_file_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./PermuteMNIST_vae_coreset_k\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_exps_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49mi, coreset_config\u001b[39m=\u001b[39;49mconfig)\n","Cell \u001b[0;32mIn[7], line 46\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(save_file_name, coreset_config)\u001b[0m\n\u001b[1;32m     44\u001b[0m     elbo\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     45\u001b[0m     nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_value_(current_model\u001b[39m.\u001b[39mparameters(), \u001b[39m5\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     current_opt\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     47\u001b[0m     ELBO_batch\u001b[39m.\u001b[39mappend(elbo\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     48\u001b[0m ELBO\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(ELBO_batch))\n","File \u001b[0;32m~/miniconda3/envs/mlmi4/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n","File \u001b[0;32m~/miniconda3/envs/mlmi4/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n","File \u001b[0;32m~/miniconda3/envs/mlmi4/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/miniconda3/envs/mlmi4/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n","File \u001b[0;32m~/miniconda3/envs/mlmi4/lib/python3.9/site-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m exp_avg\u001b[39m.\u001b[39;49mmul_(beta1)\u001b[39m.\u001b[39;49madd_(grad, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta1)\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad\u001b[39m.\u001b[39mconj(), value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[39mif\u001b[39;00m capturable \u001b[39mor\u001b[39;00m differentiable:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for i in tqdm(range(0,3), desc=\"Running experiment\", position=0):\n","    # print(\"====================== Run %d =====================\"%i)\n","    config = CoresetConfig('vae-k-center', None, 200)\n","    Accuracies = run_experiments(save_file_name=\"./PermuteMNIST_vae_coreset_k\" + \"_exps_%d.pkl\"%i, coreset_config=config)"]},{"cell_type":"code","execution_count":29,"id":"t9cZmNDoh2hz","metadata":{"id":"t9cZmNDoh2hz"},"outputs":[],"source":["all_accs = np.zeros((10, 10))\n","for i in range(10):\n","    file_name = \"./PermuteMNIST_vae_coreset_k\" + \"_exps_%d.pkl\"%i\n","    with open(file_name, 'rb') as f:\n","        accs = pickle.load( f)\n","        all_accs[i] = np.array(accs)\n","        \n"]},{"cell_type":"code","execution_count":31,"id":"c4ef2c22","metadata":{},"outputs":[{"data":{"text/plain":["array([0.97643   , 0.973575  , 0.97293667, 0.971915  , 0.9705    ,\n","       0.968635  , 0.96676857, 0.96444625, 0.96121889, 0.957998  ])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["all_accs.mean(axis=0)"]},{"cell_type":"code","execution_count":32,"id":"4a2OO39nh2kT","metadata":{"id":"4a2OO39nh2kT"},"outputs":[{"data":{"text/plain":["array([0.0009122 , 0.00134597, 0.00100061, 0.00072588, 0.00114553,\n","       0.00112048, 0.00108458, 0.00134941, 0.00132648, 0.00136708])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["all_accs.std(axis=0)"]},{"cell_type":"code","execution_count":null,"id":"iK4PucNDaSph","metadata":{"id":"iK4PucNDaSph"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"id":"MTODLFcWYkKp","metadata":{"id":"MTODLFcWYkKp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"013925e264834599a452ba23c3d14f87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"111b8b1004df4ef3b03986eb77b27306":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138b4c88fea941ccad005afb8c89576c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b7f1c6e6ad744489a902dffc1dd5090":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c9b00bceb1544e78228be3e72b5c293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4afd3484fda4398960a2e49b45f3c8e","IPY_MODEL_3c3186242d384c508635b2e1e3be39d1","IPY_MODEL_cb8c323fa82c4ff1a388dd510f3a5323"],"layout":"IPY_MODEL_111b8b1004df4ef3b03986eb77b27306"}},"21a51e5f20a845b9bf04c55b021bbe21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d75c83f803fd45e09dcba05c2f39c6d0","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32cb5d519d234f159278b4918d452ee0","value":28881}},"2597272853ea4cbca38b7df239b34d66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f08315dc19e44cda8cef02b3a76330a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32cb5d519d234f159278b4918d452ee0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34ae145f8de941dd9b229582b1ca0ddf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99b4aa392a0a4ffda3a34abb75ff4ad8","IPY_MODEL_21a51e5f20a845b9bf04c55b021bbe21","IPY_MODEL_7eb525148f90423c84d30dfba68aaf0f"],"layout":"IPY_MODEL_9ca4bae40e6041b59457bfcf77943b36"}},"36178f80a99b49f38cae0a86e53addcb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b903ed1907d4b0b999f8f412e99e7b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c3186242d384c508635b2e1e3be39d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df75ad974e75418885f10f7ff1596462","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e657fea4955c4ccaa5349c80c5a2ec98","value":1648877}},"40c39a4d63774220b219e440af38c14a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c9317678e1446cf87760a297b02b426","IPY_MODEL_df700a9dbba3473f81cbd04515f01dc6","IPY_MODEL_c7827847da6a485586d686ae2609db0d"],"layout":"IPY_MODEL_1b7f1c6e6ad744489a902dffc1dd5090"}},"41938c7b57f54b16ae343d7f7f1ecfe1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48ff1a06940d41039d06c508e09b3dab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ae4258ee979445fb3c750e759162de5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c9317678e1446cf87760a297b02b426":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36178f80a99b49f38cae0a86e53addcb","placeholder":"​","style":"IPY_MODEL_013925e264834599a452ba23c3d14f87","value":"100%"}},"7074a85086994b83be9a1a33d25f7494":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bebc51e2fff8425f97c005eab6b3a7bd","placeholder":"​","style":"IPY_MODEL_2597272853ea4cbca38b7df239b34d66","value":" 4542/4542 [00:00&lt;00:00, 217392.38it/s]"}},"723675e7685e40bf81d34d4af2a087a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb525148f90423c84d30dfba68aaf0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_138b4c88fea941ccad005afb8c89576c","placeholder":"​","style":"IPY_MODEL_d277df76b23947159431df94442952bb","value":" 28881/28881 [00:00&lt;00:00, 2094179.06it/s]"}},"857d8d542e9548dd94131b8432fdd122":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c924cb85b61b407083dd1d0d02daddec","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e2bc882f19d49519a286b7c9c03287c","value":4542}},"85d88060ee4e48d2863d500c8dc126ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a664e2628d54d2997e9eaee85fa40f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99b4aa392a0a4ffda3a34abb75ff4ad8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48ff1a06940d41039d06c508e09b3dab","placeholder":"​","style":"IPY_MODEL_c36d4e95255d4dd58ce7511b6ce0e63f","value":"100%"}},"9ca4bae40e6041b59457bfcf77943b36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e2bc882f19d49519a286b7c9c03287c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5537173fa5448cd97cf82656c13c813":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae5980193b6b4412b27fb7da58d12f2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af425e13852245ff86f4f49741793c05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cc2d9b1e75bb471a8d635eccf8d9d1a3","IPY_MODEL_857d8d542e9548dd94131b8432fdd122","IPY_MODEL_7074a85086994b83be9a1a33d25f7494"],"layout":"IPY_MODEL_a5537173fa5448cd97cf82656c13c813"}},"bebc51e2fff8425f97c005eab6b3a7bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c36d4e95255d4dd58ce7511b6ce0e63f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c7827847da6a485586d686ae2609db0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d88060ee4e48d2863d500c8dc126ca","placeholder":"​","style":"IPY_MODEL_f0198315a5ac4b2b8a54e4f885984c8c","value":" 9912422/9912422 [00:00&lt;00:00, 165972890.87it/s]"}},"c924cb85b61b407083dd1d0d02daddec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb8c323fa82c4ff1a388dd510f3a5323":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ae4258ee979445fb3c750e759162de5","placeholder":"​","style":"IPY_MODEL_41938c7b57f54b16ae343d7f7f1ecfe1","value":" 1648877/1648877 [00:00&lt;00:00, 49302731.77it/s]"}},"cc2d9b1e75bb471a8d635eccf8d9d1a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f08315dc19e44cda8cef02b3a76330a","placeholder":"​","style":"IPY_MODEL_ae5980193b6b4412b27fb7da58d12f2c","value":"100%"}},"d277df76b23947159431df94442952bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d75c83f803fd45e09dcba05c2f39c6d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df700a9dbba3473f81cbd04515f01dc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a664e2628d54d2997e9eaee85fa40f9","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b903ed1907d4b0b999f8f412e99e7b3","value":9912422}},"df75ad974e75418885f10f7ff1596462":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e657fea4955c4ccaa5349c80c5a2ec98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6b5a150126141e2a4128cd7c096852a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0198315a5ac4b2b8a54e4f885984c8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4afd3484fda4398960a2e49b45f3c8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_723675e7685e40bf81d34d4af2a087a9","placeholder":"​","style":"IPY_MODEL_e6b5a150126141e2a4128cd7c096852a","value":"100%"}}}}},"nbformat":4,"nbformat_minor":5}
