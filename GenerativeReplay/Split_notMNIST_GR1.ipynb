{"cells":[{"cell_type":"markdown","metadata":{"id":"8SuudyZ0H1Pu"},"source":["### Settings for Colab..."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28351,"status":"ok","timestamp":1678095967303,"user":{"displayName":"Jiajun He","userId":"11208084986033535177"},"user_tz":0},"id":"K6Pis0ceHxLW","outputId":"3e50621a-c871-4548-b75f-df2d982818a9"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6K0DezmzHy8T"},"outputs":[],"source":["# ! cp -R \"/content/drive/MyDrive/Advanced Machine Learning Project/GenerativeReplay/alg\" ./"]},{"cell_type":"markdown","metadata":{"id":"424mZUIqEnT0"},"source":["### Load Data and Packages"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7q4gN0pIAffZ"},"outputs":[],"source":["def set_up_parent_imports():\n","    import sys, os\n","    module_path = os.path.abspath(os.path.join('..'))\n","    if module_path not in sys.path:\n","        sys.path.append(module_path)\n","\n","set_up_parent_imports()\n","import torch\n","from torch import nn\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torchvision import datasets\n","from torchvision import transforms\n","from alg.vcl_net import MultiHeadVCLSplitNotMNIST, Initialization\n","from alg.kcenter import KCenter\n","from datasets import MultiTaskDataset\n","import pickle"]},{"cell_type":"markdown","metadata":{"id":"gofGoq2IEqwm"},"source":["### Define Generator"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ijpWFHEDEtU4"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, z_dim, task_num=5):\n","        super().__init__()\n","        self.task_num = task_num\n","        self.fcs = nn.ModuleList([nn.Linear(784+task_num if i == 0 else 500+task_num, 500) for i in range(6)])\n","        self.head1 = nn.Linear(500+task_num, z_dim)\n","        self.head2 = nn.Linear(500+task_num, z_dim)\n","    def forward(self, x, task_ids):\n","        t = nn.functional.one_hot(task_ids.long(), num_classes=self.task_num)\n","        h = x\n","        for i in self.fcs:\n","            h = nn.ReLU()(i(torch.cat([h, t], dim=-1)))\n","        loc = self.head1(torch.cat([h, t], dim=-1))\n","        scale = torch.exp(self.head2(torch.cat([h, t], dim=-1)))\n","        return loc, scale\n","class Decoder(nn.Module):\n","    def __init__(self, z_dim, task_num=5):\n","        super().__init__()\n","        self.task_num = task_num\n","        self.fcs = nn.ModuleList([nn.Linear(z_dim+task_num if i == 0 else 500+task_num, 500) for i in range(6)])\n","        self.fc6 = nn.Linear(500+task_num, 784)\n","    def forward(self, z, task_ids):\n","        t = nn.functional.one_hot(task_ids.long(), num_classes=self.task_num)\n","        h = z\n","        for i in self.fcs:\n","            h = nn.ReLU()(i(torch.cat([h, t], dim=-1)))\n","        logits = self.fc6(torch.cat([h, t], dim=-1))\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"C097XeaAEuWg"},"source":["### Training Fcn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fVAvew49Affb"},"outputs":[],"source":["def run(verbose=True, use_coreset=False):\n","\n","    generator_models = {}\n","    solvers = {}\n","\n","\n","    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","    test_x_all = []\n","    test_y_all = []\n","    test_task_i_all = []\n","\n","    if use_coreset:\n","        coreset_x = None  \n","        coreset_y = None\n","        coreset_size = 40\n","        random_coreset = True\n","\n","    batch_size = 1000\n","    accuracies = {}\n","    n_epochs = 120\n","    n_epochs_generator = 300\n","\n","\n","    previous_model, coreset_task_mask = None, None\n","\n","    dataset = MultiTaskDataset('split notMNIST', device)\n","    for task_i in range(5):\n","        train_x, train_y, test_x, test_y = dataset.get_task_dataset(task_i)\n","        test_x_all.append(test_x)\n","        test_y_all.append(test_y)\n","        test_task_i_all.append(torch.ones((test_x.shape[0]), dtype=int) * task_i)\n","\n","        # define current model\n","        if task_i == 0:\n","            current_model = MultiHeadVCLSplitNotMNIST(num_heads=1, initialization=Initialization.RANDOM).to(device)\n","            current_model.set_prior(MultiHeadVCLSplitNotMNIST(num_heads=1, initialization=Initialization.DEFAULT).to(device))\n","        else:\n","            current_model = MultiHeadVCLSplitNotMNIST.new_from_prior(previous_model)\n","            current_model.add_head(initialization=Initialization.RANDOM)\n","            # Set last head the same as the first head (this was in the initial implementation in tf) TODO investigate\n","            # current_model.heads[-1].set_params(*previous_model.heads[0].get_params())\n","\n","        assert len(current_model.heads) == task_i + 1\n","        current_opt = torch.optim.Adam(current_model.parameters(), lr=0.001)\n","\n","\n","        if use_coreset:\n","            if random_coreset:\n","                coreset_idx = np.random.choice(train_x.shape[0], coreset_size, False)\n","            else:\n","                coreset_idx = np.array(KCenter(coreset_size).fit_transform(train_x.cpu().detach().numpy()))\n","            train_idx = np.delete(np.arange(train_x.shape[0]), coreset_idx)\n","            new_coreset_x = train_x[coreset_idx]\n","            new_coreset_y = train_y[coreset_idx]\n","            new_coreset_task_mask = torch.ones((new_coreset_x.shape[0]), dtype=int) * task_i\n","            train_x = train_x[train_idx]\n","            train_y = train_y[train_idx]\n","\n","            if coreset_x == None:\n","                coreset_x = new_coreset_x\n","                coreset_y = new_coreset_y\n","                coreset_task_mask = new_coreset_task_mask\n","            else:\n","                coreset_x = torch.cat([new_coreset_x, coreset_x])\n","                coreset_y = torch.cat([new_coreset_y, coreset_y])\n","                coreset_task_mask = torch.cat([new_coreset_task_mask, coreset_task_mask])\n","                # \"For all the algorithms with coresets, we choose 40 examples from each task to include into the coresets\"\n","        \n","        ########################################################################\n","        ####################### train the generator first ######################\n","        # train generator\n","        new_decoder = Decoder(50).to(device)\n","        new_encoder = Encoder(50).to(device)\n","\n","        batch_size_g = 256\n","        ELBOs = []\n","        optimizer = torch.optim.Adam(list(new_decoder.parameters())+list(new_encoder.parameters()), lr=0.001)\n","        for e in tqdm(range(n_epochs_generator)):\n","            elbos = []\n","            for batch in range(int(np.ceil(train_x.shape[0]/batch_size_g))):\n","                b_idx0 = batch_size_g*batch\n","                b_idx1 = batch_size_g*batch+batch_size_g\n","                batch_x = train_x[b_idx0: b_idx1]\n","                tasks_x = torch.ones(batch_x.shape[0], device=batch_x.device) * task_i\n","                # if task != 0: also generate some dataset from the old generator for training\n","                if task_i != 0:\n","                    with torch.no_grad():\n","                        for task_j in range(task_i):\n","                            z_old = torch.randn(batch_x.shape[0], 50, device=device)\n","                            tasks_old = torch.ones(batch_x.shape[0], device=batch_x.device) * task_j\n","                            batch_x_old = nn.Sigmoid()(old_decoder(z_old, tasks_old))\n","                            batch_x = torch.cat([batch_x, batch_x_old], dim=0)\n","                            tasks_x = torch.cat([tasks_x, tasks_old], dim=0)\n","                            if verbose and batch == 0 and e == 0:\n","                                print(\"Generating from old distributions...\")\n","                                show_x = batch_x_old[:16].cpu().numpy().reshape(16, 28, 28)\n","                                show_x = np.hstack([show_x[i] for i in range(16)])\n","\n","                                plt.imshow(show_x)\n","                                plt.title(\"Generated Old Images from Task %d\"%task_j)\n","                                plt.show()\n","                z_loc, z_scale = new_encoder(batch_x, tasks_x)\n","                z = z_loc + torch.randn_like(z_scale) * z_scale\n","                outputs = new_decoder(z, tasks_x)\n","                loss = nn.BCELoss(reduction=\"none\")(nn.Sigmoid()(outputs), batch_x).sum() / batch_x.shape[0]\n","                loss = loss + torch.distributions.kl_divergence(torch.distributions.Normal(z_loc, z_scale), torch.distributions.Normal(0, 1)).sum() / train_x.shape[0]\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","                elbos.append(loss.item())\n","            ELBOs.append(np.mean(elbos))\n","        ########################################################################\n","\n","        ELBO = []\n","        for epoch in (tqdm if verbose else iter)(range(n_epochs)):\n","            ELBO_batch = []\n","            for batch in range(int(np.ceil(train_x.shape[0] / batch_size))):\n","                batch_idx0 = batch * batch_size\n","                batch_idx1 = batch * batch_size + batch_size\n","                \n","                current_opt.zero_grad()\n","                batch_x = train_x[batch_idx0: batch_idx1]\n","                batch_y = train_y[batch_idx0: batch_idx1]\n","                batch_task =  torch.ones(batch_x.shape[0], device=batch_x.device) * task_i\n","\n","                # generate samples following old distributions \n","                if task_i != 0:\n","                    for task_j in range(task_i):\n","                        with torch.no_grad():\n","                            tasks_old = torch.ones(batch_x.shape[0], device=batch_x.device) * task_j\n","                            old_z = torch.randn(batch_x.shape[0], 50, device=device)\n","                            old_x = nn.Sigmoid()(old_decoder(old_z, tasks_old))\n","                            # predict using old models\n","                            old_y = nn.Softmax(-1)(torch.stack(previous_model.predict(old_x, task_j, 100), 0)).mean(0)\n","                            old_y = old_y.argmax(-1)\n","                        batch_x = torch.cat([old_x, batch_x], dim=0)\n","                        batch_y = torch.cat([old_y, batch_y], dim=0)\n","                        batch_task = torch.cat([tasks_old, batch_task])\n","\n","\n","                elbo = current_model.calculate_ELBO(x=batch_x, \n","                                                    y=batch_y, \n","                                                    n_particles=1,\n","                                                    task_i_mask=batch_task.long().cpu(),\n","                                                    dataset_size=train_x.shape[0] * (task_i+1))\n","                elbo.backward()\n","                nn.utils.clip_grad_value_(current_model.parameters(), 5)\n","                current_opt.step()\n","                ELBO_batch.append(elbo.item())\n","            ELBO.append(np.mean(ELBO_batch))\n","        if verbose:\n","            plt.plot(ELBO)\n","            plt.yscale(\"log\")\n","            plt.show()\n","        acc = []\n","        for idx in range(len(test_x_all)):\n","            test_x_tensor = test_x_all[idx]\n","            test_y_tensor = test_y_all[idx]\n","            test_task_i_mask_tensor = test_task_i_all[idx]\n","            pred_y = []\n","            with torch.no_grad():\n","                for batch in range(int(np.ceil(test_x_tensor.shape[0] / batch_size))):\n","                    batch_idx0 = batch * batch_size\n","                    batch_idx1 = batch * batch_size + batch_size\n","                    pred_logit_samples = nn.Softmax(-1)(torch.stack(current_model.predict(test_x_tensor[batch_idx0:batch_idx1], test_task_i_mask_tensor[batch_idx0:batch_idx1], 100), 0)).mean(0)\n","                    pred_y.append(pred_logit_samples.argmax(-1))\n","                pred_y = torch.cat(pred_y)\n","                _acc = (pred_y == test_y_tensor).cpu().numpy().mean()\n","                acc.append(_acc)\n","        if verbose:\n","            if use_coreset:\n","                print(\"Accuracy by the propagation model\", acc)\n","            else:\n","                print(\"Task {:d}, Accuracy: \".format(task_i), acc)\n","        if use_coreset == False:\n","            accuracies[task_i] = acc\n","\n","        if use_coreset:\n","            # calculate prediction model\n","            pred_model = MultiHeadVCLSplitNotMNIST.new_from_prior(current_model)\n","            pred_opt = torch.optim.Adam(pred_model.parameters(), lr=0.001)\n","\n","            ELBO = []\n","            for epoch in (tqdm if verbose else iter)(range(n_epochs)):\n","                ELBO_batch = []\n","                for batch in range(int(np.ceil(coreset_x.shape[0] / batch_size))):\n","                    batch_idx0 = batch * batch_size\n","                    batch_idx1 = batch * batch_size + batch_size\n","                    pred_opt.zero_grad()\n","                    elbo = pred_model.calculate_ELBO(x=coreset_x[batch_idx0: batch_idx1], \n","                                                    y=coreset_y[batch_idx0: batch_idx1], \n","                                                    task_i_mask=coreset_task_mask[batch_idx0: batch_idx1],\n","                                                    n_particles=1,\n","                                                    dataset_size=coreset_x.shape[0])\n","                    elbo.backward()\n","                    nn.utils.clip_grad_value_(pred_model.parameters(), 5)\n","                    pred_opt.step()\n","                    ELBO_batch.append(elbo.item())\n","                ELBO.append(np.mean(ELBO_batch))\n","            if verbose:\n","                plt.plot(ELBO)\n","                plt.show()\n","\n","            acc = []\n","            for idx in range(len(test_x_all)):\n","                test_x_tensor = test_x_all[idx]     \n","                test_y_tensor = test_y_all[idx]\n","                test_task_i_mask_tensor = test_task_i_all[idx]\n","                pred_y = []\n","                with torch.no_grad():\n","                    for batch in range(int(np.ceil(test_x_tensor.shape[0] / batch_size))):\n","                        batch_idx0 = batch * batch_size\n","                        batch_idx1 = batch * batch_size + batch_size\n","                        pred_logit_samples = nn.Softmax(-1)(torch.stack(pred_model.predict(test_x_tensor[batch_idx0:batch_idx1], test_task_i_mask_tensor[batch_idx0:batch_idx1], 100), 0)).mean(0)\n","                        pred_y.append(pred_logit_samples.argmax(-1))\n","                    pred_y = torch.cat(pred_y)\n","                    _acc = (pred_y == test_y_tensor).cpu().numpy().mean()\n","                    acc.append(_acc)\n","            accuracies[task_i] = acc\n","            if verbose:\n","                print(\"Task {:d}, Accuracy: \".format(task_i), acc)\n","\n","\n","        previous_model = current_model\n","        old_decoder = new_decoder\n","        old_encoder = new_encoder\n","        generator_models[task_i] = [new_decoder, new_encoder]\n","        solvers[task_i] = current_model if not use_coreset else pred_model\n","\n","\n","    # with open(\"/content/drive/MyDrive/Advanced Machine Learning Project/GenerativeReplay/Split_MNIST_GR1_models.pkl\", \"wb\") as f:\n","    #     pickle.dump(generator_models, f)\n","    #     pickle.dump(solvers, f)\n","\n","    return accuracies, generator_models, solvers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8367354,"status":"ok","timestamp":1678130447017,"user":{"displayName":"Jiajun He","userId":"11208084986033535177"},"user_tz":0},"id":"K8PcJDzSAgtn","outputId":"2e26d6a5-dae2-4318-8ee5-3cfe46d1a2c0"},"outputs":[],"source":["for i in range(10):\n","    print(\"============================ Exp %d ============================\"%i)\n","    accs, generator_models, solvers = run(False, False)\n","    with open(\"./Split_notMNIST_GR1_models_exp_%d.pkl\"%i, \"wb\") as f:\n","        pickle.dump([accs, generator_models, solvers], f)\n","    print(accs)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"NQI669fGAffd"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: [0.979296066252588], 1: [0.9834368530020704, 0.9717514124293786], 2: [0.9772256728778468, 0.9642184557438794, 0.966542750929368], 3: [0.9813664596273292, 0.9661016949152542, 0.966542750929368, 0.9358490566037736], 4: [0.9772256728778468, 0.9642184557438794, 0.966542750929368, 0.9433962264150944, 0.9630872483221476]}\n","{0: [0.9813664596273292], 1: [0.9855072463768116, 0.9642184557438794], 2: [0.9875776397515528, 0.9661016949152542, 0.9758364312267658], 3: [0.9855072463768116, 0.967984934086629, 0.9758364312267658, 0.9320754716981132], 4: [0.9772256728778468, 0.9642184557438794, 0.9776951672862454, 0.9471698113207547, 0.9530201342281879]}\n","{0: [0.989648033126294], 1: [0.9855072463768116, 0.967984934086629], 2: [0.9855072463768116, 0.9661016949152542, 0.9684014869888475], 3: [0.9834368530020704, 0.96045197740113, 0.9684014869888475, 0.9471698113207547], 4: [0.979296066252588, 0.9585687382297552, 0.9684014869888475, 0.9528301886792453, 0.9362416107382551]}\n","{0: [0.9772256728778468], 1: [0.979296066252588, 0.9717514124293786], 2: [0.9751552795031055, 0.9642184557438794, 0.9646840148698885], 3: [0.9813664596273292, 0.9661016949152542, 0.9684014869888475, 0.939622641509434], 4: [0.9813664596273292, 0.9661016949152542, 0.9646840148698885, 0.9471698113207547, 0.959731543624161]}\n","{0: [0.979296066252588], 1: [0.9834368530020704, 0.967984934086629], 2: [0.9834368530020704, 0.9717514124293786, 0.9684014869888475], 3: [0.9855072463768116, 0.9661016949152542, 0.9702602230483272, 0.9415094339622642], 4: [0.979296066252588, 0.967984934086629, 0.9776951672862454, 0.9509433962264151, 0.9546979865771812]}\n","{0: [0.9834368530020704], 1: [0.9834368530020704, 0.9623352165725048], 2: [0.9813664596273292, 0.9698681732580038, 0.9646840148698885], 3: [0.9813664596273292, 0.9698681732580038, 0.9646840148698885, 0.9471698113207547], 4: [0.9813664596273292, 0.9623352165725048, 0.966542750929368, 0.9490566037735849, 0.9580536912751678]}\n","{0: [0.9813664596273292], 1: [0.9834368530020704, 0.9661016949152542], 2: [0.9834368530020704, 0.9661016949152542, 0.9684014869888475], 3: [0.9834368530020704, 0.9566854990583804, 0.9702602230483272, 0.9415094339622642], 4: [0.9772256728778468, 0.9472693032015066, 0.966542750929368, 0.9433962264150944, 0.947986577181208]}\n","{0: [0.9834368530020704], 1: [0.9834368530020704, 0.9623352165725048], 2: [0.9834368530020704, 0.9623352165725048, 0.9739776951672863], 3: [0.9855072463768116, 0.967984934086629, 0.9758364312267658, 0.9452830188679245], 4: [0.979296066252588, 0.9698681732580038, 0.9721189591078067, 0.9528301886792453, 0.947986577181208]}\n","{0: [0.9855072463768116], 1: [0.9875776397515528, 0.9642184557438794], 2: [0.9855072463768116, 0.967984934086629, 0.9739776951672863], 3: [0.9813664596273292, 0.9698681732580038, 0.9776951672862454, 0.9358490566037736], 4: [0.9834368530020704, 0.967984934086629, 0.9776951672862454, 0.939622641509434, 0.9614093959731543]}\n","{0: [0.9813664596273292], 1: [0.9834368530020704, 0.9717514124293786], 2: [0.9834368530020704, 0.9698681732580038, 0.9702602230483272], 3: [0.9834368530020704, 0.9661016949152542, 0.9721189591078067, 0.9452830188679245], 4: [0.979296066252588, 0.967984934086629, 0.9721189591078067, 0.9433962264150944, 0.9446308724832215]}\n"]}],"source":["# Load results\n","for i in range(10):\n","    with open(\"./Split_notMNIST_GR1_models_exp_%d.pkl\"%i, 'rb') as f:\n","        accs, generator_models, solvers = pickle.load(f)\n","        print(accs)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["8SuudyZ0H1Pu","424mZUIqEnT0","gofGoq2IEqwm"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"mlmi4","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"8989f891c30e0a24d4dfc555fd9de385bfc71786fcc0499d22146b0688236dec"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0d3772205b114897967e56dc15427427":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba4c4e363b554c40a91c71dd2e2e9c1b","placeholder":"​","style":"IPY_MODEL_548a6b4d79ce4f8a9de58e0c9a2d9f7e","value":"100%"}},"1837a3b402244ecab1488fd107eb7f5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8013735c597419a9989904605fa7be2","IPY_MODEL_74a845aa0dcc4a59b3c2148f49a3dab2","IPY_MODEL_ede9bb27f6ac429c94f0f79abe1aa781"],"layout":"IPY_MODEL_757b9a23f2604d37a4468a943663ca82"}},"2160cbbd2d15453188e4446198ab4962":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75031d680b6e4749978d4a1197609ac6","max":1648877,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7015271a2cc7474892a5a57eb2e2b3d0","value":1648877}},"217e6655e3da469ca14c161d050e0b32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4180075a25743a195adaa0cb1183400","max":4542,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea26b83450b94d7d865d2cadc8c960eb","value":4542}},"2ad5353edaa542a6b50b449f4755772a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ef69fd7b79447d195b6e6392752ebc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3152ae13033f4f2c8984f034b0b859b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3521feb0171e4cca9100a5cdd3171bac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3748de37405142b298f8968610b58dc8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"385a295841e840cb9927e93f57f40ad3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41d0f9dfe7914897ab73160362615626":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5391630bea8e46b4837fa4647d154d20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d39b2015da4fe28cc25704c11c43aa","max":9912422,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f8b10e9ce8941b2b64304518b52bd9f","value":9912422}},"548a6b4d79ce4f8a9de58e0c9a2d9f7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56ada28f85384ee1b96cae13ff882cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57d2b2cde02b412da872caee1ee83916":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d3772205b114897967e56dc15427427","IPY_MODEL_2160cbbd2d15453188e4446198ab4962","IPY_MODEL_5949a57cd07d4c46b5d0dc4c2088a560"],"layout":"IPY_MODEL_2ef69fd7b79447d195b6e6392752ebc6"}},"5949a57cd07d4c46b5d0dc4c2088a560":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8235f7b3ad8146ed8c4c59eefaa1f195","placeholder":"​","style":"IPY_MODEL_41d0f9dfe7914897ab73160362615626","value":" 1648877/1648877 [00:00&lt;00:00, 50079953.92it/s]"}},"5baa19440b4a4dcaa08bf049ab81d017":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f8b10e9ce8941b2b64304518b52bd9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"630bd84d6bfb42818d4e94da1ea5701e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_886f640c71cb45a3a9497cdd008ec8c0","placeholder":"​","style":"IPY_MODEL_56ada28f85384ee1b96cae13ff882cd3","value":"100%"}},"7015271a2cc7474892a5a57eb2e2b3d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74a845aa0dcc4a59b3c2148f49a3dab2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3152ae13033f4f2c8984f034b0b859b4","max":28881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3521feb0171e4cca9100a5cdd3171bac","value":28881}},"75031d680b6e4749978d4a1197609ac6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"757b9a23f2604d37a4468a943663ca82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77a7c94b5bdd4bd9ae0f5aa737a67242":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1fff26c89a340e5912966ad8907d65e","placeholder":"​","style":"IPY_MODEL_3748de37405142b298f8968610b58dc8","value":" 4542/4542 [00:00&lt;00:00, 174004.45it/s]"}},"78b440b2e49c411a832d264030383a7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8235f7b3ad8146ed8c4c59eefaa1f195":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"877f899a410a4b4ea9043052b6f9be93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95575f94a41345bfb4414b635c7680ca","IPY_MODEL_217e6655e3da469ca14c161d050e0b32","IPY_MODEL_77a7c94b5bdd4bd9ae0f5aa737a67242"],"layout":"IPY_MODEL_bc5bdbcc8a124de686b59f3b89f035b2"}},"886f640c71cb45a3a9497cdd008ec8c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88f25cfaa4344081bcf19aeb16aacca5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fbd0f2f9b514a0b9c86a0ba9ffd1321":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78b440b2e49c411a832d264030383a7b","placeholder":"​","style":"IPY_MODEL_2ad5353edaa542a6b50b449f4755772a","value":" 9912422/9912422 [00:00&lt;00:00, 179775975.70it/s]"}},"95575f94a41345bfb4414b635c7680ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f25cfaa4344081bcf19aeb16aacca5","placeholder":"​","style":"IPY_MODEL_c65130f72f14459c838fe859a252b76f","value":"100%"}},"97979298e4b4446aba8dfe734bfee092":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_630bd84d6bfb42818d4e94da1ea5701e","IPY_MODEL_5391630bea8e46b4837fa4647d154d20","IPY_MODEL_8fbd0f2f9b514a0b9c86a0ba9ffd1321"],"layout":"IPY_MODEL_5baa19440b4a4dcaa08bf049ab81d017"}},"98bac4d812724cf0bf86c0beb64f8c6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4180075a25743a195adaa0cb1183400":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab215655f03d4965b1eb212d177a80f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9d39b2015da4fe28cc25704c11c43aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba4c4e363b554c40a91c71dd2e2e9c1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5bdbcc8a124de686b59f3b89f035b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c65130f72f14459c838fe859a252b76f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8013735c597419a9989904605fa7be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab215655f03d4965b1eb212d177a80f7","placeholder":"​","style":"IPY_MODEL_98bac4d812724cf0bf86c0beb64f8c6b","value":"100%"}},"e1fff26c89a340e5912966ad8907d65e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea26b83450b94d7d865d2cadc8c960eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ede9bb27f6ac429c94f0f79abe1aa781":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_385a295841e840cb9927e93f57f40ad3","placeholder":"​","style":"IPY_MODEL_f3476dc4413b479f87fa67793dbfa17a","value":" 28881/28881 [00:00&lt;00:00, 1512003.77it/s]"}},"f3476dc4413b479f87fa67793dbfa17a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
